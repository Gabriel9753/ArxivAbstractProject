{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from chromadb.utils import embedding_functions\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.trychroma.com/guides\n",
    "CHROMA_DATA_PATH = \"chroma_data/\"\n",
    "# EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "EMBED_MODEL = \"all-mpnet-base-v2\"\n",
    "COLLECTION_NAME = \"arxiv_papers\"\n",
    "BATCH_SIZE = 5000\n",
    "\n",
    "CHROMA_DATA_PATH = os.path.join(CHROMA_DATA_PATH, EMBED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119503, 14)\n"
     ]
    }
   ],
   "source": [
    "cache_dir = 'cache'\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "\n",
    "parquet_path = '../data/arxiv_metadata_sample.parquet.gzip'\n",
    "arxiv_df = pd.read_parquet(parquet_path)\n",
    "\n",
    "print(arxiv_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(sample):\n",
    "    title = sample['title']\n",
    "    abstract = sample['abstract']\n",
    "\n",
    "    # remove special characters\n",
    "    title = title.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "    abstract = abstract.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "\n",
    "    # remove multiple spaces\n",
    "    title = ' '.join(title.split())\n",
    "    abstract = ' '.join(abstract.split())\n",
    "\n",
    "    return f\"Title: {title} - Abstract: {abstract}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>update_date</th>\n",
       "      <th>title_words</th>\n",
       "      <th>abstract_words</th>\n",
       "      <th>mapped_categories</th>\n",
       "      <th>amount_categories</th>\n",
       "      <th>update_year</th>\n",
       "      <th>super_categories</th>\n",
       "      <th>amount_super_categories</th>\n",
       "      <th>super_categories_str</th>\n",
       "      <th>super_category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2306.01499</td>\n",
       "      <td>Can LLMs like GPT-4 outperform traditional AI ...</td>\n",
       "      <td>Recent investigations show that large langua...</td>\n",
       "      <td>[cs.CL, cs.LG]</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>15</td>\n",
       "      <td>163</td>\n",
       "      <td>[Computation and Language, Machine Learning]</td>\n",
       "      <td>2</td>\n",
       "      <td>2023</td>\n",
       "      <td>[Artificial Intelligence, Artificial Intellige...</td>\n",
       "      <td>2</td>\n",
       "      <td>Computer Science and Artificial Intelligence</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>Title: Can LLMs like GPT-4 outperform traditio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2312.05019</td>\n",
       "      <td>Vision-based Learning for Drones: A Survey</td>\n",
       "      <td>Drones as advanced cyber-physical systems ar...</td>\n",
       "      <td>[cs.RO, cs.AI]</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>6</td>\n",
       "      <td>181</td>\n",
       "      <td>[Robotics, Artificial Intelligence]</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>[Artificial Intelligence, Artificial Intellige...</td>\n",
       "      <td>2</td>\n",
       "      <td>Computer Science and Artificial Intelligence</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>Title: Vision-based Learning for Drones: A Sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2307.14359</td>\n",
       "      <td>A new derivative-free optimization method: Gau...</td>\n",
       "      <td>Optimization methods are essential in solvin...</td>\n",
       "      <td>[math.OC, cs.LG]</td>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>8</td>\n",
       "      <td>114</td>\n",
       "      <td>[Optimization and Control, Machine Learning]</td>\n",
       "      <td>2</td>\n",
       "      <td>2023</td>\n",
       "      <td>[Engineering and Technology, Artificial Intell...</td>\n",
       "      <td>2</td>\n",
       "      <td>Computer Science and Artificial Intelligence E...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>Title: A new derivative-free optimization meth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0  2306.01499  Can LLMs like GPT-4 outperform traditional AI ...   \n",
       "1  2312.05019         Vision-based Learning for Drones: A Survey   \n",
       "2  2307.14359  A new derivative-free optimization method: Gau...   \n",
       "\n",
       "                                            abstract        categories  \\\n",
       "0    Recent investigations show that large langua...    [cs.CL, cs.LG]   \n",
       "1    Drones as advanced cyber-physical systems ar...    [cs.RO, cs.AI]   \n",
       "2    Optimization methods are essential in solvin...  [math.OC, cs.LG]   \n",
       "\n",
       "  update_date  title_words  abstract_words  \\\n",
       "0  2023-06-05           15             163   \n",
       "1  2024-01-03            6             181   \n",
       "2  2023-07-28            8             114   \n",
       "\n",
       "                              mapped_categories  amount_categories  \\\n",
       "0  [Computation and Language, Machine Learning]                  2   \n",
       "1           [Robotics, Artificial Intelligence]                  2   \n",
       "2  [Optimization and Control, Machine Learning]                  2   \n",
       "\n",
       "   update_year                                   super_categories  \\\n",
       "0         2023  [Artificial Intelligence, Artificial Intellige...   \n",
       "1         2024  [Artificial Intelligence, Artificial Intellige...   \n",
       "2         2023  [Engineering and Technology, Artificial Intell...   \n",
       "\n",
       "   amount_super_categories                               super_categories_str  \\\n",
       "0                        2       Computer Science and Artificial Intelligence   \n",
       "1                        2       Computer Science and Artificial Intelligence   \n",
       "2                        2  Computer Science and Artificial Intelligence E...   \n",
       "\n",
       "            super_category                                               text  \n",
       "0  Artificial Intelligence  Title: Can LLMs like GPT-4 outperform traditio...  \n",
       "1  Artificial Intelligence  Title: Vision-based Learning for Drones: A Sur...  \n",
       "2  Artificial Intelligence  Title: A new derivative-free optimization meth...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_df['text'] = arxiv_df.apply(text_processing, axis=1)\n",
    "arxiv_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadatas(arxiv_df):\n",
    "    metadatas = []\n",
    "    for _, row in arxiv_df.iterrows():\n",
    "        metadatas.append({\n",
    "            \"update_date\": row['update_date'],\n",
    "            \"title_words\": row['title_words'],\n",
    "            \"abstract_words\": row['abstract_words'],\n",
    "            \"super_category\": row['super_category'],\n",
    "            \"mapped_categories\": \";\".join(row['mapped_categories']),\n",
    "        })\n",
    "\n",
    "    return metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection(client, collection_name, embedding_function):\n",
    "    collection = client.create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=embedding_function,\n",
    "        metadata={\"hnsw:space\": \"cosine\"},\n",
    "        get_or_create=True,\n",
    "    )\n",
    "\n",
    "    return collection\n",
    "\n",
    "def delete_collection_data(client, collection, collection_name):\n",
    "    print(f\"Deleting data from collection {collection_name} with {collection.count()} documents\")\n",
    "    client.delete_collection(collection_name)\n",
    "\n",
    "def get_random_samples_from_collection(collection, n_samples):\n",
    "    collection_ids = collection.get()[\"ids\"]\n",
    "    random_ids = np.random.choice(collection_ids, n_samples, replace=False).tolist()\n",
    "    documents = collection.get(ids=random_ids)\n",
    "    return documents\n",
    "\n",
    "def upsert_data(collection, arxiv_df, metadatas, batch_size):\n",
    "    for i in tqdm(range(0, len(arxiv_df), batch_size)):\n",
    "        collection.upsert(\n",
    "            documents=arxiv_df['text'].iloc[i:i + batch_size].tolist(),\n",
    "            ids=arxiv_df['id'].iloc[i:i + batch_size].tolist(),\n",
    "            metadatas=metadatas[i:i + batch_size],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w:\\Workspaces\\Python\\Studium\\Master\\ArxivAbstractProject\\.venv311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting data from collection arxiv_papers with 0 documents\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3635407c07f94f31a7560e4055461ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# delete the collection if it exists\n",
    "client = chromadb.PersistentClient(path=CHROMA_DATA_PATH)\n",
    "\n",
    "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=EMBED_MODEL,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "collection = create_collection(client, COLLECTION_NAME, embedding_func)\n",
    "\n",
    "# delete if you want to start fresh but then you need to create the collection again\n",
    "# delete_collection_data(client, collection, COLLECTION_NAME)\n",
    "# collection = create_collection(client, COLLECTION_NAME, embedding_func)\n",
    "\n",
    "# create metadatas\n",
    "metadatas = create_metadatas(arxiv_df)\n",
    "\n",
    "# upsert data (insert or update if exists)\n",
    "# upsert_data(collection, arxiv_df, metadatas, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      " Deep Learning and veganism \n",
      "\n",
      "#####   ID: 2012.05995   #####\n",
      "Distance: 0.49146878719329834\n",
      "Metadata: {'abstract_words': 165, 'mapped_categories': 'Genomics', 'super_category': 'Biological Sciences and Medicine', 'title_words': 10, 'update_date': '2022-03-15'}\n",
      "Title: Towards a robust out-of-the-box neural network model for genomic\n",
      "data - Abstract: The accurate prediction of biological features from\n",
      "genomic data is paramount for precision medicine and sustainable agriculture.\n",
      "For decades, neural network models have been widely popular in\n",
      "fields like computer vision, astrophysics and targeted marketing given their\n",
      "prediction accuracy and their robust performance under big data settings.\n",
      "Yet neural network models have not made a successful transition\n",
      "into the medical and biological world due to the ubiquitous\n",
      "characteristics of biological data such as modest sample sizes, sparsity,\n",
      "and extreme heterogeneity. Here, we investigate the robustness, generalization potential\n",
      "and prediction accuracy of widely used convolutional neural network and\n",
      "natural language processing models with a variety of heterogeneous genomic\n",
      "datasets. Mainly, recurrent neural network models outperform convolutional neural network\n",
      "models in terms of prediction accuracy, overfitting and transferability across\n",
      "the datasets under study. While the perspective of a robust\n",
      "out-of-the-box neural network model is out of reach, we identify\n",
      "certain model characteristics that translate well across datasets and could\n",
      "serve as a baseline model for translational researchers.\n",
      "\n",
      "\n",
      "#####   ID: 2309.0297   #####\n",
      "Distance: 0.519930362701416\n",
      "Metadata: {'abstract_words': 188, 'mapped_categories': 'Risk Management;Machine Learning;Optimization and Control;Computational Finance', 'super_category': 'Economics and Finance', 'title_words': 13, 'update_date': '2024-02-15'}\n",
      "Title: On the Impact of Feeding Cost Risk in Aquaculture\n",
      "Valuation and Decision Making - Abstract: We study the effect\n",
      "of stochastic feeding costs on animal-based commodities with particular focus\n",
      "on aquaculture. More specifically, we use soybean futures to infer\n",
      "on the stochastic behaviour of salmon feed, which we assume\n",
      "to follow a Schwartz-2-factor model. We compare the decision of\n",
      "harvesting salmon using a decision rule assuming either deterministic or\n",
      "stochastic feeding costs, i.e. including feeding cost risk. We identify\n",
      "cases, where accounting for stochastic feeding costs leads to significant\n",
      "improvements as well as cases where deterministic feeding costs are\n",
      "a good enough proxy. Nevertheless, in all of these cases,\n",
      "the newly derived rules show superior performance, while the additional\n",
      "computational costs are negligible. From a methodological point of view,\n",
      "we demonstrate how to use Deep-Neural-Networks to infer on the\n",
      "decision boundary that determines harvesting or continuation, improving on more\n",
      "classical regression-based and curve-fitting methods. To achieve this we use\n",
      "a deep classifier, which not only improves on previous results\n",
      "but also scales well for higher dimensional problems, and in\n",
      "addition mitigates effects due to model uncertainty, which we identify\n",
      "in this article. effects due to model uncertainty, which we\n",
      "identify in this article.\n",
      "\n",
      "\n",
      "#####   ID: 1705.03094   #####\n",
      "Distance: 0.5358447432518005\n",
      "Metadata: {'abstract_words': 105, 'mapped_categories': 'Genomics;Quantitative Methods', 'super_category': 'Data Science and Information Theory', 'title_words': 11, 'update_date': '2017-05-10'}\n",
      "Title: DeepMetabolism: A Deep Learning System to Predict Phenotype from\n",
      "Genome Sequencing - Abstract: Life science is entering a new\n",
      "era of petabyte-level sequencing data. Converting such big data to\n",
      "biological insights represents a huge challenge for computational analysis. To\n",
      "this end, we developed DeepMetabolism, a biology-guided deep learning system\n",
      "to predict cell phenotypes from transcriptomics data. By integrating unsupervised\n",
      "pre-training with supervised training, DeepMetabolism is able to predict phenotypes\n",
      "with high accuracy (PCC>0.92), high speed (<30 min for >100\n",
      "GB data using a single GPU), and high robustness (tolerate\n",
      "up to 75% noise). We envision DeepMetabolism to bridge the\n",
      "gap between genotype and phenotype and to serve as a\n",
      "springboard for applications in synthetic biology and precision medicine.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define query\n",
    "words_per_line = 10\n",
    "# define papers to show\n",
    "top_n_papers = 3\n",
    "query = \"Deep Learning and veganism\"\n",
    "print(\"Query:\\n\", query, \"\\n\")\n",
    "query_results = collection.query(query_texts=[query], n_results=top_n_papers)\n",
    "for _id, _doc, _dist, _meta in zip(query_results[\"ids\"][0], query_results[\"documents\"][0], query_results[\"distances\"][0], query_results[\"metadatas\"][0]):\n",
    "    print(f\"#####   ID: {_id}   #####\")\n",
    "    print(f\"Distance: {_dist}\")\n",
    "    print(f\"Metadata: {_meta}\")\n",
    "    _doc_lines = _doc.split()\n",
    "    for i in range(0, len(_doc_lines), words_per_line):\n",
    "        print(\" \".join(_doc_lines[i:i + words_per_line]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>embedding</th>\n",
       "      <th>super_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001.0039</td>\n",
       "      <td>Title: TGCat, The Chandra Transmission Grating...</td>\n",
       "      <td>[0.05119134858250618, -0.018094409257173538, 0...</td>\n",
       "      <td>Astrophysics and Cosmology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001.0051</td>\n",
       "      <td>Title: Lukewarm dark matter: Bose condensation...</td>\n",
       "      <td>[0.018889665603637695, -0.08081771433353424, 0...</td>\n",
       "      <td>Astrophysics and Cosmology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001.0057</td>\n",
       "      <td>Title: Arrested phase separation in reproducin...</td>\n",
       "      <td>[-0.011269346810877323, -0.04270167648792267, ...</td>\n",
       "      <td>Biological Sciences and Medicine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           document  \\\n",
       "0  1001.0039  Title: TGCat, The Chandra Transmission Grating...   \n",
       "1  1001.0051  Title: Lukewarm dark matter: Bose condensation...   \n",
       "2  1001.0057  Title: Arrested phase separation in reproducin...   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [0.05119134858250618, -0.018094409257173538, 0...   \n",
       "1  [0.018889665603637695, -0.08081771433353424, 0...   \n",
       "2  [-0.011269346810877323, -0.04270167648792267, ...   \n",
       "\n",
       "                     super_category  \n",
       "0        Astrophysics and Cosmology  \n",
       "1        Astrophysics and Cosmology  \n",
       "2  Biological Sciences and Medicine  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = collection.get(include=[\"metadatas\", \"documents\", \"embeddings\"])\n",
    "df = pd.DataFrame({\n",
    "    \"id\": response[\"ids\"],\n",
    "    \"document\": response[\"documents\"],\n",
    "    \"embedding\": response[\"embeddings\"],\n",
    "    \"super_category\": [x[\"super_category\"] for x in response[\"metadatas\"]],\n",
    "})\n",
    "# all_categories = df[\"categories\"].explode().unique()\n",
    "# cat_mapping = {cat: i for i, cat in enumerate(all_categories)}\n",
    "# df[\"cat_id\"] = df[\"categories\"].apply(lambda x: cat_mapping[x])\n",
    "# df.loc[:, all_categories] = df[\"categories\"].apply(lambda x: [1 if cat in x else 0 for cat in all_categories]).tolist()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from renumics import spotlight\n",
    "\n",
    "# spotlight.show(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, df, cat_ids):\n",
    "        self.ids = df[\"id\"].values\n",
    "        self.embeddings = torch.tensor(df[\"embedding\"].tolist(), dtype=torch.float32)\n",
    "        self.categories = torch.tensor(df[\"cat_id\"].values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.ids[idx], self.embeddings[idx], self.categories[idx]\n",
    "\n",
    "class EmbeddingModel(torch.nn.Module):\n",
    "    def __init__(self, n_emb_size, n_categories):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(n_emb_size, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 256)\n",
    "        self.fc3 = torch.nn.Linear(256, n_categories)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# train val split\n",
    "emb_dataset = EmbeddingDataset(df, cat_mapping)\n",
    "train_size = int(0.8 * len(emb_dataset))\n",
    "val_size = len(emb_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(emb_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Val size: {len(val_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EmbeddingModel(len(df[\"embedding\"].values[0]), len(all_categories)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, epochs=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for _, emb, cat in train_loader:\n",
    "            emb, cat = emb.to(device), cat.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(emb)\n",
    "            loss = criterion(output, cat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for _, emb, cat in val_loader:\n",
    "                emb, cat = emb.to(device), cat.to(device)\n",
    "                output = model(emb)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += cat.size(0)\n",
    "                correct += (predicted == cat).sum().item()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Accuracy: {100 * correct / total}\")\n",
    "\n",
    "train(model, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "classes = arxiv_df['mapped_categories'].explode().unique()\n",
    "classes = {c: i for i, c in enumerate(classes)}\n",
    "num_classes = len(classes)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "arxiv_df['class'] = arxiv_df['mapped_categories'].apply(lambda x: classes[x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init=\"k-means++\", n_clusters=num_classes, n_init=4, random_state=0)\n",
    "estimator = make_pipeline(StandardScaler(), kmeans).fit(df[\"embedding\"].tolist())\n",
    "# estimator = make_pipeline(kmeans).fit(df[\"embedding\"].tolist())\n",
    "\n",
    "df[\"cluster\"] = estimator.predict(df[\"embedding\"].tolist())\n",
    "merged_df = pd.merge(df[['id', 'cluster']], arxiv_df, on=\"id\")\n",
    "\n",
    "accuracy = metrics.accuracy_score(merged_df['class'], merged_df['cluster'])\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
